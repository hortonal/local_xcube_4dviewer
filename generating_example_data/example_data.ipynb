{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "049bf2e4-b35c-411c-8148-c381501cab6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "from shutil import rmtree\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyproj import Transformer\n",
    "from dataclasses import dataclass\n",
    "from numpy.typing import NDArray\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ccd01b-f40b-4bf4-b1d6-eb22594e0484",
   "metadata": {},
   "source": [
    "## Prepare data structures and coordinate extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15978f45-7526-4833-8248-9884a5ab1862",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BoundingBox:\n",
    "    min_x: float\n",
    "    max_x: float\n",
    "    min_y: float\n",
    "    max_y: float\n",
    "    min_z: float\n",
    "    max_z: float\n",
    "\n",
    "@dataclass\n",
    "class ResultVariable:\n",
    "    name: str\n",
    "    units: str\n",
    "    data: NDArray\n",
    "\n",
    "@dataclass\n",
    "class Resolution:\n",
    "    x: float\n",
    "    y: float\n",
    "    z: float\n",
    "\n",
    "@dataclass\n",
    "class ResultCollection:\n",
    "    name: str\n",
    "    bounding_box: BoundingBox\n",
    "    resolution: Resolution\n",
    "    variables: List[ResultVariable]\n",
    "    \n",
    "    \n",
    "def _convert_lat_lon_str_to_decimal(coordinate: str) -> float:\n",
    "    \"\"\"\n",
    "    Convert a latitude or longitude string in Decimal Minutes format to a decimal.\n",
    "\n",
    "    Explicitly this works with the formats found in the bottle file of: '66ยก51.502N'\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coordinate : str\n",
    "        Input latitude or longitude\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Decimalised latitude or longitude\n",
    "    \"\"\"\n",
    "    # If we were being strict, we'd do a regex check here first but it's just not necessary for the ad-hoc use case.\n",
    "    major, minor = coordinate.split('ยก')\n",
    "\n",
    "    direction_multiplier = -1 if 'S' in minor or 'W' in minor else 1\n",
    "    for char in ['N', 'S', 'E', 'W']:\n",
    "        minor = minor.replace(char, '')\n",
    "\n",
    "    return direction_multiplier * (float(major) + float(minor) / 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84479ba3-781c-4571-9b8d-1e389aa0a0e4",
   "metadata": {},
   "source": [
    "## Translate csv files into regular grids, extracting variables, extents and units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccc606bf-e53a-4014-8617-b41a473bc527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Target CRS for the viewer - EPSG:3413\n",
    "target_proj4 = \"+proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\"\n",
    "# target_proj4 = \"+proj=stere +lat_0=90 +lat_ts=75 +lon_0=0 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +type=crs\"\n",
    "\n",
    "# This is an artificial width for the sake of visualising a column of values in the front end.\n",
    "width = 5000\n",
    "\n",
    "# We have to interpolate onto a regular z axis. This sets how many samples to take vertically\n",
    "nb_vertical_samples = 50\n",
    "\n",
    "# Arbitrary date as the data is not supplied with one.\n",
    "dates = [datetime(2022, 9, 9)]\n",
    "\n",
    "# Build a list of result objects. 1 per file.\n",
    "\n",
    "results = []\n",
    "\n",
    "for file_id in ['1', '2']:\n",
    "    \n",
    "    # Open the file and figure out the basic extent details.\n",
    "    bottle_file_path = os.path.join('example_data', f'Station_BB{file_id}.csv')\n",
    "\n",
    "    # There are some funky bytes in these files requiring the non-standard encoding.\n",
    "    df = pd.read_csv(bottle_file_path, encoding=\"ISO-8859-1\")\n",
    "    df.sort_values(\"Depth_m\", inplace=True)\n",
    "\n",
    "    depths = df.Depth_m.values\n",
    "\n",
    "    # Simple interp values at a regular interval:\n",
    "    depths_interpolated = np.linspace(depths.min(), depths.max(), nb_vertical_samples)\n",
    "    vertical_resolution = (depths.max() - depths.min()) / (nb_vertical_samples - 1)\n",
    "\n",
    "    # Take the coords from the file and covert to our desired crs\n",
    "    transformer = Transformer.from_crs('epsg:4326', target_proj4)\n",
    "    lat = _convert_lat_lon_str_to_decimal(df.Latitude[0])\n",
    "    lon = _convert_lat_lon_str_to_decimal(df.Longitude[0])\n",
    "\n",
    "    x, y = transformer.transform(lat, lon)\n",
    "\n",
    "    bounding_box_3d = BoundingBox(min_x=x - width / 2, max_x=x + width / 2,\n",
    "                                  min_y=y - width / 2, max_y=y + width / 2,\n",
    "                                  min_z=-depths.max() - vertical_resolution / 2, max_z=-depths.min() + vertical_resolution / 2)\n",
    "\n",
    "    result_variables = []\n",
    "    result_collection = ResultCollection(\n",
    "        name=f\"bottle-station-{file_id}\",\n",
    "        bounding_box=bounding_box_3d,\n",
    "        variables=result_variables,\n",
    "        # As we synthesize extra x and y values below, we must adjust the x/y resolution accordingly.\n",
    "        resolution=Resolution(x=width/2, y=width/2, z=vertical_resolution))\n",
    "    results.append(result_collection)\n",
    "    \n",
    "    for field in ['Salinity_psu', 'Temperature_C']:\n",
    "\n",
    "        raw_data = df[field].values\n",
    "\n",
    "        # Note, the depths must be increasing for np.interp to work properly\n",
    "        data = np.interp(depths_interpolated[::-1], depths, raw_data)\n",
    "\n",
    "        # Convert data into [z, y, x] format\n",
    "        data = np.expand_dims(np.expand_dims(data, axis=1), axis=2)\n",
    "        # Work around an xcube limitation, for x, y axes to have more than 1 value:\n",
    "        data = np.repeat(np.repeat(data, 2, axis=1), 2, axis=2)\n",
    "        \n",
    "        # csv convention has the column suffixed with units.\n",
    "        units = field.split(\"_\")[-1]\n",
    "        data_set_name = f\"manitoba-{field.replace('_' + units, '')}-{file_id}\"\n",
    "        \n",
    "        result_variables.append(ResultVariable(name=data_set_name, units=units, data=data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf2c01fa-e444-46b5-87c9-d6c528439a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quickly check our result structure is as expected.\n",
    "assert results[0].variables[0].units == 'psu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c002bd82-f9a3-480f-af21-412386ac7bcb",
   "metadata": {},
   "source": [
    "## Now save in an xcube compatible format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0009fc3-b596-4562-8b5b-c47bf599f8e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/xcube/util/plugin.py:176: UserWarning: Initializing xcube plugin 'xcube_4d_viewer' took 278 ms, consider code optimization. (For example, avoid eager import of packages, consider lazy loading of resources, etc.)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import netCDF4\n",
    "from rasterio.crs import CRS\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from xcube.core.chunk import chunk_dataset\n",
    "from xcube.core.store import new_data_store\n",
    "\n",
    "for result in results:\n",
    "    with netCDF4.Dataset('tmp.nc', 'w', diskless=True) as nc:\n",
    "        \n",
    "        # Get first variable as a reference\n",
    "        data = result.variables[0].data\n",
    "        bounding_box = result.bounding_box\n",
    "        resolution = result.resolution\n",
    "\n",
    "        # Create dimensions\n",
    "        nc.createDimension('z', data.shape[0])\n",
    "        nc.createDimension('y', data.shape[1])\n",
    "        nc.createDimension('x', data.shape[2])\n",
    "\n",
    "        # Create variables\n",
    "        z_var = nc.createVariable('z', np.float64, ('z'))\n",
    "        z_var.standard_name = 'Height'\n",
    "        z_var.axis = 'z'\n",
    "\n",
    "        y_var = nc.createVariable('y', np.float64, ('y'))\n",
    "        y_var.standard_name = 'North'\n",
    "        y_var.axis = 'y'\n",
    "\n",
    "        x_var = nc.createVariable('x', np.float64, ('x'))\n",
    "        x_var.standard_name = 'East'\n",
    "        x_var.axis = 'x'\n",
    "\n",
    "        z = np.arange(bounding_box.min_z + resolution.z / 2.0, bounding_box.max_z, resolution.z)\n",
    "        y = np.arange(bounding_box.min_y + resolution.y / 2.0, bounding_box.max_y, resolution.y)\n",
    "        x = np.arange(bounding_box.min_x + resolution.x / 2.0, bounding_box.max_x, resolution.x)\n",
    "\n",
    "        z_var[:] = z\n",
    "        y_var[:] = y\n",
    "        x_var[:] = x\n",
    "\n",
    "        # Set up CRS\n",
    "        crs = CRS.from_proj4(target_proj4)\n",
    "        nc_crs = nc.createVariable('spatial_ref', 'i4')\n",
    "        nc_crs.spatial_ref = crs.to_wkt()\n",
    "\n",
    "        for variable in result.variables:\n",
    "            var = nc.createVariable(variable.name, \"float32\", ('z', 'y', 'x'), fill_value=999)\n",
    "            var.units = variable.units\n",
    "            var.long_name = variable.name\n",
    "            var.short_name = variable.name\n",
    "            var[:, :, :] = variable.data\n",
    "            var.grid_mapping = 'spatial_ref'\n",
    "\n",
    "        chunk_size=256\n",
    "        store = new_data_store('file', root='./xcube-server-data/')\n",
    "        dataset = xr.open_dataset(xr.backends.NetCDF4DataStore(nc))\n",
    "\n",
    "        for variable in result.variables:\n",
    "            dataset.variables[variable.name].attrs['4d_viewer_layer_type'] = 'heatmap3d'  # or heightmap\n",
    "\n",
    "        dataset.attrs['4d_viewer_ui_path'] = '/example_data/'\n",
    "        chunked_dataset = chunk_dataset(dataset, dict(z=chunk_size, y=chunk_size, x=chunk_size), format_name='zarr')\n",
    "\n",
    "        store.write_data(chunked_dataset, f'{result.name}.zarr', replace=True)\n",
    "        store.write_data(chunked_dataset, f'{result.name}.levels', replace=True,\n",
    "                         base_dataset_id=f'{result.name}.zarr', agg_methods=\"first\")        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
